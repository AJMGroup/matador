#!/usr/bin/env python
# coding: utf-8
""" Run many CASTEP calculations from multiple res,
a single cell and a single param file.

Jobs in progress are listed in jobs.txt, failed
jobs are moved to bad_castep, completed jobs are
moved to completed and listed in finished_cleanly.txt.

Based on run.pl, run2.pl and PyAIRSS class CastepRunner.

Matthew Evans 2016
"""

from __future__ import print_function
# matador modules
from matador.scrapers.castep_scrapers import cell2dict, param2dict
from matador.utils.print_utils import print_failure, print_warning
from matador.compute import FullRelaxer

# standard library
from os.path import isfile
from collections import defaultdict
from traceback import print_exc
import argparse
import multiprocessing as mp
import glob


class BatchRun:
    """ A class that implements the running of multiple CASTEP jobs from a series
    of .res files and single cell and param files.
    """
    def __init__(self, *args, **kwargs):
        """ Check directory has valid contents and prepare log files and directories if
        not already prepared, then begin running calculations.
        """
        # analyse parallel allocation
        self.args = kwargs
        self.debug = self.args.get('debug')
        if self.args.get('verbosity') is None:
            self.verbosity = 0
        else:
            self.verbosity = self.args.get('verbosity')
        if self.args.get('no_reopt'):
            self.reopt = False
        else:
            self.reopt = True
        self.all_cores = mp.cpu_count()
        self.seed = self.args.get('seed')
        self.limit = self.args.get('limit')
        self.archer = self.args.get('archer')
        self.bnl = self.args.get('bnl')
        self.executable = self.args.get('executable')
        self.rough = self.args.get('rough')
        self.spin = self.args.get('spin')
        if self.args.get('executable') is None:
            self.executable = 'castep'
        valid = True
        if self.args.get('nprocesses') is not None:
            self.nprocesses = self.args['nprocesses']
        else:
            self.nprocesses = 1
        if self.args.get('ncores') is not None:
            self.ncores = self.args['ncores']
        else:
            self.ncores = int(self.all_cores / self.nprocesses)
        if self.args.get('nnodes') is not None:
            self.nnodes = self.args['nnodes']
            print_warning('Attempting to run over multiple nodes, please ensure \
                           that you are using Intel MPI or this will produce \
                           unexpected behaviour!')
        else:
            self.nnodes = None
        try:
            assert (self.nnodes is None or self.nnodes >= 1)
            assert self.ncores >= 1
            assert self.nprocesses >= 1
        except(AssertionError):
            print_failure('Invalid number of cores, nodes or processes.')
            exit()
        if self.ncores*self.nprocesses > self.all_cores:
            print_warning('Requested more cores (' + str(self.ncores*self.nprocesses) +
                          ') than available (' + str(self.all_cores) + ').' +
                          '(Maybe you are using a queueing system).')
        # scan directory for files to run
        self.cell_dict, cell_success = cell2dict(self.seed + '.cell', db=False)
        if not cell_success:
            valid = False
            print_failure('Failed to parse cell file')
        self.param_dict, param_success = param2dict(self.seed + '.param', db=False)
        if not param_success:
            valid = False
            print_failure('Failed to parse param file')
        self.file_lists = defaultdict(list)
        self.file_lists['res'] = glob.glob('*.res')
        if len(self.file_lists['res']) < 1:
            valid = False
            print_failure('run3 requires at least 1 res file in folder, found' +
                          str(len(self.file_lists['res'])))
        if 'geom_max_iter' not in self.param_dict and \
                self.param_dict['task'].upper() in ['GEOMETRYOPTIMISATION',
                                                    'GEOMETRYOPTIMIZATION']:
            valid = False
            print_failure('geom_max_iter is unset, please fix this.')
        if 'geom_max_iter' in self.param_dict and int(self.param_dict['geom_max_iter']) < 20:
            valid = False
            print_failure('geom_max_iter is only ' +
                          str(self.param_dict['geom_max_iter']) + '... quitting.')
        if self.args.get('conv_cutoff'):
            try:
                if isfile('cutoff.conv'):
                    with open('cutoff.conv', 'r') as f:
                        flines = f.readlines()
                        self.cutoffs = []
                        for line in flines:
                            self.cutoffs.append(int(line))
                else:
                    raise RuntimeError
            except:
                valid = False
                print_failure('Error with cutoff.conv file.')
        else:
            self.cutoffs = None
        if self.args.get('conv_kpt'):
            try:
                if isfile('kpt.conv'):
                    with open('kpt.conv', 'r') as f:
                        flines = f.readlines()
                        self.kpts = []
                        for line in flines:
                            self.kpts.append(float(line))
                else:
                    raise RuntimeError
            except:
                print_exc()
                valid = False
                print_failure('Error with kpt.conv file.')
        else:
            self.kpts = None
        if not valid:
            exit('Exiting...')
        # delete source from cell and param
        del self.cell_dict['source']
        del self.param_dict['source']
        # prepare folders and text files
        self.paths = dict()
        self.paths['completed_dir'] = 'completed'
        self.paths['failed_dir'] = 'bad_castep'
        self.paths['jobs_fname'] = 'jobs.txt'
        self.paths['completed_fname'] = 'finished_cleanly.txt'
        self.paths['failures_fname'] = 'failures.txt'
        if not isfile(self.paths['jobs_fname']):
            with open(self.paths['jobs_fname'], 'a'):
                pass
        if not isfile(self.paths['completed_fname']):
            with open(self.paths['completed_fname'], 'a'):
                pass
        if not isfile(self.paths['failures_fname']):
            with open(self.paths['failures_fname'], 'a'):
                pass

    def spawn(self):
        """ Spawn processes to perform calculations. """
        procs = []
        for ind in range(self.nprocesses):
            procs.append(mp.Process(target=self.perform_new_calculations,
                         args=(self.file_lists['res'], self.paths)))
        try:
            for proc in procs:
                proc.start()
        except(KeyboardInterrupt, SystemExit, RuntimeError):
            print_exc()
            for proc in procs:
                proc.terminate()
            exit('Killing running jobs and exiting...')

    def perform_new_calculations(self, res_list, paths):
        """ Perform all calculations that have not already
        failed or finished to completion. """
        job_count = 0
        for res in res_list:
            running = False
            with open(paths['jobs_fname'], 'r') as job_file:
                flines = job_file.readlines()
                for line in flines:
                    if res in line:
                        running = True
                        break
            if not running:
                if self.limit is not None:
                    if job_count == self.limit:
                        print(self.limit)
                        raise SystemExit
                with open(paths['jobs_fname'], 'a') as job_file:
                    job_file.write(res+'\n')
                # create full relaxer object for creation and running of job
                try:
                    job_count += 1
                    relaxer = FullRelaxer(ncores=self.ncores,
                                          nnodes=self.nnodes,
                                          node=None,
                                          res=res,
                                          param_dict=self.param_dict,
                                          cell_dict=self.cell_dict,
                                          executable=self.executable,
                                          rough=self.rough,
                                          archer=self.archer,
                                          bnl=self.bnl,
                                          debug=self.debug,
                                          verbosity=self.verbosity,
                                          reopt=self.reopt,
                                          spin=self.spin,
                                          conv_cutoff=self.cutoffs,
                                          conv_kpt=self.kpts)
                    if relaxer.success:
                        with open(paths['completed_fname'], 'a') as job_file:
                            job_file.write(res+'\n')
                    else:
                        with open(paths['failures_fname'], 'a') as job_file:
                            job_file.write(res+'\n')
                except(KeyboardInterrupt, SystemExit, RuntimeError):
                    print_exc()
                    raise SystemExit
        return


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        prog='run3',
        description='Run multiple CASTEP geometry optmizations from a series of .res \
                     files and single cell and param files. The geometry optimization will \
                     be split into four chunks of 2 iteratiosn, followed by chunks of 20 \
                     iterations, until geom_max_iter is reached in the param file. \
                     Successful runs will be moved to completed, crashes/failures will go to \
                     bad_castep and initial res files will go into input. Running jobs will \
                     be listed in jobs.txt and those that completed cleanly will be listed \
                     in finished_cleanly.txt.',
        epilog='Written by Matthew Evans (2016), based primarily on run.pl and run2.pl \
                by Chris Pickard and Andrew Morris and PyAIRSS CastepRunner by Jamie Wynn.')
    parser.add_argument('seed', type=str,
                        help='cell and param seed to use as template for calculations')
    parser.add_argument('-nc', '--ncores', type=int,
                        help='number of cores CASTEP per job [DEFAULT=cpu_count/nprocesses]')
    parser.add_argument('-np', '--nprocesses', type=int,
                        help='number of concurrent calculations, i.e. number \
                              of concurrent mpiruns [DEFAULT=1]')
    parser.add_argument('-nn', '--nnodes', type=int,
                        help='number of nodes per job, i.e. number of nodes \
                              using -nc cores [DEFAULT=1]. REQUIRES Intel MPI as \
                              found on e.g. Darwin HPC.')
    parser.add_argument('-exec', '--executable', type=str,
                        help='specify path to or name of executable')
    parser.add_argument('--no_reopt', action='store_true',
                        help='do not run geometry optimisation again after first success')
    parser.add_argument('-d', '--debug', action='store_true',
                        help='debug output')
    parser.add_argument('-v', '--verbosity', type=int,
                        help='integer to set level of verbosity')
    parser.add_argument('--archer', action='store_true',
                        help='use aprun over mpirun')
    parser.add_argument('--bnl', action='store_true',
                        help='use srun over mpirun')
    parser.add_argument('--conv_cutoff', action='store_true',
                        help='run all res files at cutoff defined in cutoff.conv file')
    parser.add_argument('--conv_kpt', action='store_true',
                        help='run all res files at kpoint spacings defined in kpt.conv file')
    parser.add_argument('--spin', action='store_true',
                        help='if not specified in .cell file, break spin symmetry on first atom')
    parser.add_argument('--rough', type=int,
                        help='choose how many cycles of 2 geometry optimization iterations \
                              to perform, decrease if lattice is nearly correct. [DEFAULT: 4].')
    parser.add_argument('-l', '--limit', type=int,
                        help='limit to n structures per run')
    args = parser.parse_args()
    runner = BatchRun(ncores=args.ncores, nprocesses=args.nprocesses, nnodes=args.nnodes,
                      debug=args.debug, verbosity=args.verbosity, seed=args.seed,
                      conv_cutoff=args.conv_cutoff, conv_kpt=args.conv_kpt,
                      limit=args.limit, archer=args.archer, bnl=args.bnl, no_reopt=args.no_reopt,
                      executable=args.executable, rough=args.rough, spin=args.spin)
    try:
        runner.spawn()
    except(KeyboardInterrupt, SystemExit):
        exit('Exiting top-level...')
