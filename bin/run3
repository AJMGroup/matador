#!/usr/bin/env python
# coding: utf-8
""" Run many CASTEP calculations from multiple res,
a single cell and a single param file.

Jobs in progress are listed in jobs.txt, failed
jobs are moved to bad_castep, completed jobs are
moved to completed and listed in finished_cleanly.txt.

Based on run.pl, run2.pl and PyAIRSS class CastepRunner.

Matthew Evans 2016
"""

from __future__ import print_function
# matador modules
from matador.scrapers.castep_scrapers import cell2dict, param2dict
from matador.utils.print_utils import print_failure, print_warning
from matador.compute import FullRelaxer
from matador.version import __version__

# standard library
from os.path import isfile
from collections import defaultdict
from traceback import print_exc
import argparse
import multiprocessing as mp
import glob


class BatchRun:
    """ A class that implements the running of multiple CASTEP jobs from a series
    of .res files and single cell and param files.
    """
    def __init__(self, *args, **kwargs):
        """ Check directory has valid contents and prepare log files and directories if
        not already prepared, then begin running calculations.
        """
        # parse args, then co-opt them for passing directly into FullRelaxer
        self.args = vars(args[0])
        self.debug = self.args.get('debug')
        self.seed = self.args['seed']
        del self.args['seed']
        if self.args.get('no_reopt'):
            self.args['reopt'] = False
        else:
            self.args['reopt'] = True
        del self.args['no_reopt']
        self.nprocesses = int(self.args['nprocesses'])
        del self.args['nprocesses']
        self.limit = self.args.get('limit')
        del self.args['limit']
        self.all_cores = mp.cpu_count()
        if self.args.get('ncores') is None:
            self.args['ncores'] = int(self.all_cores / self.nprocesses)
        if self.args.get('nnodes') != 1:
            print_warning('Attempting to run over multiple nodes, please ensure \
                           that you are using Intel MPI or this will produce \
                           unexpected behaviour!')
        try:
            assert self.args['nnodes'] >= 1
            assert self.args['ncores'] >= 1
            assert self.nprocesses >= 1
        except AssertionError:
            print_exc()
            print_failure('Invalid number of cores, nodes or processes.')
            exit()
        if self.args['ncores']*self.nprocesses > self.all_cores:
            print_warning('Requested more cores (' + str(self.args['ncores']*self.nprocesses) +
                          ') than available (' + str(self.all_cores) + ').' +
                          '(Maybe you are using a queueing system).')
        # read cell/param files
        exts = ['cell', 'param']
        for ext in exts:
            if not isfile('{}.{}'.format(self.seed, ext)):
                print_failure('Failed to find {} file, {}.{}'.format(ext, self.seed, ext))
                exit()
        self.cell_dict, cell_success = cell2dict(self.seed + '.cell', db=False)
        if not cell_success:
            print_failure('Failed to parse cell file')
            exit()
        self.param_dict, param_success = param2dict(self.seed + '.param', db=False)
        if not param_success:
            print_failure('Failed to parse param file')
            exit()

        # scan directory for files to run
        self.file_lists = defaultdict(list)
        self.file_lists['res'] = glob.glob('*.res')
        if len(self.file_lists['res']) < 1:
            print_failure('run3 requires at least 1 res file in folder, found' +
                          str(len(self.file_lists['res'])))
            exit()

        # do some prelim checks of parameters
        if 'geom_max_iter' not in self.param_dict and \
                self.param_dict['task'].upper() in ['GEOMETRYOPTIMISATION',
                                                    'GEOMETRYOPTIMIZATION']:
            print_failure('geom_max_iter is unset, please fix this.')
            exit()
        if 'geom_max_iter' in self.param_dict and int(self.param_dict['geom_max_iter']) < 20:
            print_failure('geom_max_iter is only ' +
                          str(self.param_dict['geom_max_iter']) + '... quitting.')
            exit()

        # check if we're doing a conv run
        if self.args.get('conv_cutoff'):
            try:
                if isfile('cutoff.conv'):
                    with open('cutoff.conv', 'r') as f:
                        flines = f.readlines()
                        self.args['conv_cutoff'] = []
                        for line in flines:
                            self.args['conv_cutoff'].append(int(line))
                else:
                    raise RuntimeError
            except:
                print_exc()
                print_failure('Error with cutoff.conv file.')
                exit()
        else:
            self.args['conv_cutoff'] = None

        if self.args.get('conv_kpt'):
            try:
                if isfile('kpt.conv'):
                    with open('kpt.conv', 'r') as f:
                        flines = f.readlines()
                        self.args['conv_kpt'] = []
                        for line in flines:
                            self.args['conv_kpt'].append(float(line))
                else:
                    raise RuntimeError
            except:
                print_exc()
                print_failure('Error with kpt.conv file.')
                exit()
        else:
            self.args['conv_kpt'] = None

        # delete source from cell and param
        del self.cell_dict['source']
        del self.param_dict['source']

        # prepare folders and text files
        self.paths = dict()
        self.paths['completed_dir'] = 'completed'
        self.paths['failed_dir'] = 'bad_castep'
        self.paths['jobs_fname'] = 'jobs.txt'
        self.paths['completed_fname'] = 'finished_cleanly.txt'
        self.paths['failures_fname'] = 'failures.txt'
        if not isfile(self.paths['jobs_fname']):
            with open(self.paths['jobs_fname'], 'a'):
                pass
        if not isfile(self.paths['completed_fname']):
            with open(self.paths['completed_fname'], 'a'):
                pass
        if not isfile(self.paths['failures_fname']):
            with open(self.paths['failures_fname'], 'a'):
                pass

    def spawn(self):
        """ Spawn processes to perform calculations. """
        procs = []
        for ind in range(self.nprocesses):
            procs.append(mp.Process(target=self.perform_new_calculations,
                         args=(self.file_lists['res'], self.paths)))
        try:
            for proc in procs:
                proc.start()
        except(KeyboardInterrupt, SystemExit, RuntimeError):
            print_exc()
            for proc in procs:
                proc.terminate()
            exit('Killing running jobs and exiting...')

    def perform_new_calculations(self, res_list, paths):
        """ Perform all calculations that have not already
        failed or finished to completion. """
        job_count = 0
        for res in res_list:
            running = False
            with open(paths['jobs_fname'], 'r') as job_file:
                flines = job_file.readlines()
                for line in flines:
                    if res in line:
                        running = True
                        break
            if not running:
                if self.limit is not None:
                    if job_count == self.limit:
                        raise SystemExit
                with open(paths['jobs_fname'], 'a') as job_file:
                    job_file.write(res+'\n')
                # create full relaxer object for creation and running of job
                try:
                    job_count += 1
                    relaxer = FullRelaxer(node=None, res=res,
                                          param_dict=self.param_dict,
                                          cell_dict=self.cell_dict,
                                          **self.args)
                    if relaxer.success:
                        with open(paths['completed_fname'], 'a') as job_file:
                            job_file.write(res+'\n')
                    else:
                        with open(paths['failures_fname'], 'a') as job_file:
                            job_file.write(res+'\n')
                except(KeyboardInterrupt, SystemExit, RuntimeError):
                    print_exc()
                    raise SystemExit
        return


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        prog='run3',
        description='Run multiple CASTEP geometry optmizations from a series of .res \
                     files and single cell and param files. The geometry optimization will \
                     be split into four chunks of 2 iteratiosn, followed by chunks of 20 \
                     iterations, until geom_max_iter is reached in the param file. \
                     Successful runs will be moved to completed, crashes/failures will go to \
                     bad_castep and initial res files will go into input. Running jobs will \
                     be listed in jobs.txt and those that completed cleanly will be listed \
                     in finished_cleanly.txt.',
        epilog='Written by Matthew Evans (2016), based primarily on run.pl and run2.pl \
                by Chris Pickard and Andrew Morris and PyAIRSS CastepRunner by Jamie Wynn.')
    parser.add_argument('--version', action='version', version='run3 operating from matador version '
                        + __version__ + '.')
    parser.add_argument('seed', type=str,
                        help='cell and param seed to use as template for calculations')
    parser.add_argument('-nc', '--ncores', type=int,
                        help='number of cores CASTEP per job [DEFAULT=cpu_count/nprocesses]')
    parser.add_argument('-np', '--nprocesses', type=int, default=1,
                        help='number of concurrent calculations, i.e. number \
                              of concurrent mpiruns [DEFAULT=1]')
    parser.add_argument('-nn', '--nnodes', type=int, default=1,
                        help='number of nodes per job, i.e. number of nodes \
                              using -nc cores [DEFAULT=1]. REQUIRES Intel MPI as \
                              found on e.g. Darwin HPC.')
    parser.add_argument('-exec', '--executable', type=str, default='castep',
                        help='specify path to or name of executable')
    parser.add_argument('--no_reopt', action='store_true', default=False,
                        help='do not run geometry optimisation again after first success')
    parser.add_argument('-d', '--debug', action='store_true', default=False,
                        help='debug output')
    parser.add_argument('-cust', '--custom_params', action='store_true', default=False,
                        help='use custom param file per structure')
    parser.add_argument('-v', '--verbosity', type=int, default=0,
                        help='integer to set level of verbosity')
    parser.add_argument('--archer', action='store_true', default=False,
                        help='use aprun over mpirun')
    parser.add_argument('--bnl', action='store_true', default=False,
                        help='use srun over mpirun')
    parser.add_argument('--conv_cutoff', action='store_true', default=False,
                        help='run all res files at cutoff defined in cutoff.conv file')
    parser.add_argument('--conv_kpt', action='store_true', default=False,
                        help='run all res files at kpoint spacings defined in kpt.conv file')
    parser.add_argument('--kpts_1D', action='store_true', default=False,
                        help='recalculate a 1D kpoint mesh of spacing specified in template cell')
    parser.add_argument('--spin', action='store_true', default=False,
                        help='if not specified in .cell file, break spin symmetry on first atom')
    parser.add_argument('--rough', type=int, default=4,
                        help='choose how many cycles of 2 geometry optimization iterations \
                              to perform, decrease if lattice is nearly correct. [DEFAULT: 4].')
    parser.add_argument('-l', '--limit', type=int, default=None,
                        help='limit to n structures per run')
    args = parser.parse_args()
    runner = BatchRun(args)
    try:
        runner.spawn()
    except(KeyboardInterrupt, SystemExit):
        exit('Exiting top-level...')
